from pymongo import MongoClient
import json
import os
from datetime import datetime
from tqdm import tqdm
import glob


def import_database_with_progress(backup_dir=None):
    # è¿æ¥é…ç½®
    MONGODB_URI = "mongodb://localhost:27017"
    DATABASE_NAME = "web"

    client = MongoClient(MONGODB_URI)
    db = client[DATABASE_NAME]

    # å¦‚æœæ²¡æœ‰æŒ‡å®šå¤‡ä»½ç›®å½•ï¼ŒæŸ¥æ‰¾æœ€æ–°çš„å¤‡ä»½
    if backup_dir is None:
        backup_dirs = glob.glob(f"{DATABASE_NAME}_backup_*")
        if not backup_dirs:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°å¤‡ä»½ç›®å½•")
            return
        # æŒ‰åˆ›å»ºæ—¶é—´æ’åºï¼Œé€‰æ‹©æœ€æ–°çš„
        backup_dirs.sort(key=lambda x: os.path.getctime(x), reverse=True)
        backup_dir = backup_dirs[0]

    print(f"ğŸ“¦ å¼€å§‹å¯¼å…¥æ•°æ®åº“: {DATABASE_NAME}")
    print(f"ğŸ“ ä»ç›®å½•å¯¼å…¥: {backup_dir}")
    print("=" * 60)

    # è·å–æ‰€æœ‰JSONæ–‡ä»¶
    json_files = glob.glob(os.path.join(backup_dir, "*.json"))
    if not json_files:
        print("âŒ å¤‡ä»½ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°JSONæ–‡ä»¶")
        return

    total_files = len(json_files)
    print(f"ğŸ“Š æ‰¾åˆ° {total_files} ä¸ªé›†åˆæ–‡ä»¶")

    # å¯¼å…¥æ¯ä¸ªé›†åˆ
    for file_path in json_files:
        coll_name = os.path.basename(file_path).replace('.json', '')
        print(f"ğŸ“ å¯¼å…¥é›†åˆ: {coll_name}")

        # è¯»å–JSONæ–‡ä»¶
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                documents = []
                for line in f:
                    if line.strip():
                        documents.append(json.loads(line))
        except Exception as e:
            print(f"  âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
            continue

        if not documents:
            print(f"  â­ï¸  è·³è¿‡ç©ºæ–‡ä»¶: {coll_name}")
            continue

        print(f"  ğŸ“Š æ‰¾åˆ° {len(documents)} ä¸ªæ–‡æ¡£")

        # è·å–é›†åˆå¼•ç”¨
        collection = db[coll_name]

        # æ£€æŸ¥é›†åˆæ˜¯å¦å·²å­˜åœ¨æ–‡æ¡£
        existing_count = collection.count_documents({})
        if existing_count > 0:
            print(f"  ğŸ”„ é›†åˆå·²å­˜åœ¨ ({existing_count} ä¸ªæ–‡æ¡£)ï¼Œå°†æ•´åˆæ•°æ®...")

        # å¯¼å…¥æ–‡æ¡£
        try:
            inserted_count = 0
            updated_count = 0

            # ä½¿ç”¨è¿›åº¦æ¡
            for doc in tqdm(documents, desc=f"  å¯¼å…¥ {coll_name}"):
                # å¤„ç†_idå­—æ®µ
                if '_id' in doc:
                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒ_idçš„æ–‡æ¡£
                    existing_doc = collection.find_one({'_id': doc['_id']})
                    if existing_doc:
                        # æ›´æ–°ç°æœ‰æ–‡æ¡£
                        collection.replace_one({'_id': doc['_id']}, doc)
                        updated_count += 1
                    else:
                        # æ’å…¥æ–°æ–‡æ¡£
                        collection.insert_one(doc)
                        inserted_count += 1
                else:
                    # æ²¡æœ‰_idå­—æ®µï¼Œç›´æ¥æ’å…¥
                    collection.insert_one(doc)
                    inserted_count += 1

            print(f"  âœ… æˆåŠŸå¯¼å…¥: {inserted_count} æ–°å¢, {updated_count} æ›´æ–°")

        except Exception as e:
            print(f"  âŒ å¯¼å…¥å¤±è´¥: {e}")

    print("=" * 60)
    print(f"ğŸ‰ æ•°æ®åº“å¯¼å…¥å®Œæˆ!")

    # æ˜¾ç¤ºå¯¼å…¥åçš„ç»Ÿè®¡ä¿¡æ¯
    print("\nğŸ“Š æ•°æ®åº“å½“å‰çŠ¶æ€:")
    for coll_name in db.list_collection_names():
        count = db[coll_name].count_documents({})
        print(f"  {coll_name}: {count} ä¸ªæ–‡æ¡£")

    client.close()


if __name__ == "__main__":
    # å¯ä»¥æŒ‡å®šå¤‡ä»½ç›®å½•ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™ä½¿ç”¨æœ€æ–°çš„å¤‡ä»½
    import_database_with_progress()
    # æˆ–è€…æŒ‡å®šç‰¹å®šç›®å½•: import_database_with_progress("web_backup_20231201_123456")